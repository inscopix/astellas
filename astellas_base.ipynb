{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook contains basic scripts for organizing Astellas data into hierarchical dicts\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import copy\n",
    "import bisect\n",
    "import pickle\n",
    "\n",
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import transform\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.spatial import distance\n",
    "import scipy.signal as signal\n",
    "import scipy.interpolate as interpolate\n",
    "from scipy import ndimage as nd\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "\n",
    "from skimage import transform\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import isx\n",
    "\n",
    "from astellaslib import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Populate dictionary with synced neural and COM data. Each experiment's stat_dict is primary data object.\n",
    "#### These should be saved as .pkl files and loaded/extended by subsequent analyses rather than created from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = ['linear_social_saline', 'linear_social_1.5mgkg_rBaclofen']\n",
    "genotypes = ['FMR1CTRL', 'FMR1KO']\n",
    "dates = ['20200401', '20200402', '20200408', '20200415']\n",
    "\n",
    "conditions = genotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize stat dict:\n",
    "stats_to_do = ['trace_mtx', 'raster_mtx', 'COM']\n",
    "stat_dict = dict()\n",
    "for c in conditions:\n",
    "    stat_dict[c] = {}\n",
    "    for e in experiments:\n",
    "        stat_dict[c][e] = {}\n",
    "        subjs = df_sub.subject_ID.loc[(df_sub.condition == e) & (df_sub.genotype == c)].values\n",
    "        for s in subjs:\n",
    "            stat_dict[c][e][s] = {}\n",
    "            for st in stats_to_do:\n",
    "                stat_dict[c][e][s][st] = []\n",
    "#stat_dict = dict(keys=conditions)\n",
    "print(stat_dict)\n",
    "\n",
    "for the_cond in conditions:\n",
    "    print('\\n\\n',the_cond)\n",
    "    for the_exp in experiments:\n",
    "        print('\\t',the_exp)\n",
    "        df_cond = df_sub.loc[(df_sub.condition == the_exp) & (df_sub.genotype == the_cond)] \n",
    "        cellsets_cond = get_cellset_paths(df_cond) # collect paths to cellsets of interest\n",
    "        subj_ids = df_cond.subject_ID.unique()\n",
    "        for subj in subj_ids: # each subject:\n",
    "            print('\\n',subj)\n",
    "            # Load cellset and gpio csv file, use them to create frame-lookup vector:\n",
    "            subj_ca_path = fix_data_path(df_cond.data_dir_ca.loc[df_cond.subject_ID == subj].values[0] )\n",
    "            subj_behav_path = fix_data_path(df_cond.data_dir_behavior.loc[df_cond.subject_ID == subj].values[0])\n",
    "            gpio_fn = [subj_ca_path + i for i in os.listdir(subj_ca_path) if 'gpio.csv' in i][0]\n",
    "            cellset_fn = [i for i in cellsets_cond if subj in i][0]\n",
    "            frame_lookup = make_frame_lookup(gpio_fn, cellset_fn)\n",
    "            cs_time = (get_cellset_timescale(cellset_fn))\n",
    "            cs_fs = round(1/(cs_time[1]) ,8)\n",
    "            print('Ca imaging sampling rate: {}'.format(cs_fs))\n",
    "\n",
    "            # Load COM csv file:\n",
    "            com_fn = behavior_dir + df_cond.behav_data_basename.loc[df_cond.subject_ID == subj].values[0] + '_COM.csv'\n",
    "            the_com = np.loadtxt(com_fn, delimiter=',')\n",
    "\n",
    "            # flip Center of mass x-values if test side is on the right. This aligns all data so that test side = left\n",
    "            the_test_side = test_side[the_exp][subj]\n",
    "            print('test side: {}'.format(the_test_side))\n",
    "            if the_test_side == 'r': \n",
    "                the_com[:,1] = -(the_com[:,1] - frame_width )\n",
    "            stat_dict[the_cond][the_exp][subj]['COM'] = the_com\n",
    "\n",
    "            # identify frames for which COM exceeded left or right threshold:\n",
    "            #left_frames = np.argwhere(the_com[:,1] < x_threshs[0]).flatten()\n",
    "            #right_frames = np.argwhere(the_com[:,1] > x_threshs[1]).flatten()\n",
    "            #middle_frames = np.asarray([i for i in range(len(the_com)) if i not in np.union1d(left_frames, right_frames) ])\n",
    "\n",
    "            # Build trace_matrix / z-matrix, event-matrix, etc:\n",
    "            [the_trace_mtx, _,the_isx_raster_mtx,] = cellset_data_volumes(cellset_fn, isx_ed_threshold=3,autosort_snr=4)\n",
    "            z_mtx = stats.zscore(the_trace_mtx, axis = 1, nan_policy = 'omit')\n",
    "\n",
    "            # Make time-base for frame-averaged activity. Each time point references the start of a behavior video frame:\n",
    "            tvect = []\n",
    "            for i in np.arange(1,max(frame_lookup)):\n",
    "                x_start = cs_time[np.argwhere(frame_lookup==i).flatten()[0]]\n",
    "                tvect.append(x_start)\n",
    "            tvect = np.asarray(tvect)\n",
    "            behav_fs = 1/(max(tvect) / len(frame_lookup))\n",
    "            print('behavior video fps: {}'.format(behav_fs))\n",
    "\n",
    "            # extract activity for each video frame and assemble into matrix:\n",
    "            frame_win = int(cs_fs * .05)\n",
    "            sub_z_mtx = np.zeros((len(tvect), z_mtx.shape[1]), dtype = np.float32)\n",
    "            sub_r_mtx = np.zeros((len(tvect), the_isx_raster_mtx.shape[1]), dtype = np.int16)\n",
    "            print('Building frame-aligned data matrix...')\n",
    "            for cellnum in range(z_mtx.shape[1]):\n",
    "                svect = []\n",
    "                rvect = []\n",
    "                for i in np.arange(1,max(frame_lookup)):\n",
    "                    x_start = int(cs_fs * cs_time[np.argwhere(frame_lookup==i).flatten()[0]])\n",
    "                    dat_vect = z_mtx[:, cellnum]\n",
    "                    svect.append(np.nanmean(dat_vect[x_start:(x_start + frame_win)]))\n",
    "                    dat_vect = the_isx_raster_mtx[:, cellnum]\n",
    "                    rvect.append(np.nanmax(dat_vect[x_start:(x_start + frame_win)]))\n",
    "                svect = np.asarray(svect)\n",
    "                rvect = np.asarray(rvect)\n",
    "                sub_z_mtx[:,cellnum] = svect.astype(np.float32)\n",
    "                sub_r_mtx[:,cellnum] = rvect.astype(np.int16)\n",
    "            #print(sub_z_mtx.shape)\n",
    "            stat_dict[the_cond][the_exp][subj]['trace_mtx'] = sub_z_mtx\n",
    "            stat_dict[the_cond][the_exp][subj]['raster_mtx'] = sub_r_mtx\n",
    "\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dictionary:\n",
    "\n",
    "fn = 'frame_aligned_data_baclofen.pkl'\n",
    "pickle.dump(stat_dict, open(fn,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Compute auROC values (event-tuning) for events/annotations of interest from stat_dict, and add fields to stat_dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sides = (95, 230)\n",
    "event_types = ['nose-to-right', ('nose-to-ag', 'nose-to-nose') ] # these should be changed according to analysis of interest\n",
    "align_pad = 200\n",
    "phase_dict = {'preference': (6500, 6500+11500)}\n",
    "n_iter = 500\n",
    "\n",
    "\n",
    "for the_cond in stat_dict.keys(): # each genotype\n",
    "    print('\\n',the_cond)\n",
    "    if 'linear' in sorted(stat_dict[the_cond].keys())[0]:\n",
    "        print('** Repeated measures detected **')\n",
    "        for the_exp in stat_dict[the_cond].keys(): # each experiment condition\n",
    "            print(the_exp)\n",
    "            \n",
    "            # This needs to be populated with per-experiment version of the following:\n",
    "            \n",
    "                        \n",
    "    else: # same as above loop but without repeated measures for each subject:\n",
    "        print('** No repeated measures detected **')\n",
    "        for the_subj in stat_dict[the_cond]: # each subject\n",
    "                print('\\t',the_subj)\n",
    "                for the_phase in sorted(phase_dict.keys()):\n",
    "                    frames = (phase_dict[the_phase][0], phase_dict[the_phase][1])\n",
    "                    for event_type in event_types:\n",
    "                        if isinstance(event_type, str):\n",
    "                            event_type = [event_type]\n",
    "                        print('\\t', event_type)\n",
    "                        # load traces and labels, extract samples in the phase of interest\n",
    "                        trace_mtx = stat_dict[the_cond][the_subj]['trace_mtx'][frames[0]:frames[1], :]\n",
    "                        df_labels = stat_dict[the_cond][the_subj]['labels']\n",
    "                        align_pnts = df_labels.frame.loc[df_labels.label.isin(event_type)].values - frames[0]\n",
    "                        #print('\\talign points: {}'.format(align_pnts[the_side][event_type]))\n",
    "\n",
    "                        # convert alignment points to raster:\n",
    "                        align_raster = np.zeros((trace_mtx.shape[0],))\n",
    "                        padded_align_pnts = align_pnts\n",
    "                        #padded_align_pnts = np.asarray(\n",
    "                        #    [np.arange(i, i+align_pad) for i in align_pnts[the_side][event_type] if (i+align_pad) < trace_mtx.shape[0]]\n",
    "                        #).flatten()\n",
    "\n",
    "                        if len(align_pnts):\n",
    "                            align_raster[padded_align_pnts] = 1\n",
    "\n",
    "                            print('\\t', trace_mtx.shape, align_raster.shape, min(np.argwhere(align_raster==1)), max(np.argwhere(align_raster==1)))\n",
    "\n",
    "                            # find cells with significant auROC based on time-shuffled distribution:\n",
    "                            auroc = []\n",
    "                            auroc_p = []\n",
    "\n",
    "                            for cellnum,the_trace in enumerate(trace_mtx.transpose()):\n",
    "                                the_auroc = metrics.roc_auc_score(align_raster, the_trace)\n",
    "                                #the_auroc = metrics.average_precision_score(align_raster[frames[0]:frames[1]], the_trace)\n",
    "                                auroc.append(the_auroc)\n",
    "                                shift_auroc = []\n",
    "                                for the_iter in range(n_iter): # time-shuffle traces for null distribution:\n",
    "                                    shift_trace = np.roll(the_trace, np.random.choice(np.arange(len(the_trace))))\n",
    "                                    shift_auroc.append(metrics.roc_auc_score(align_raster, shift_trace) )\n",
    "\n",
    "                                    # precision-recall curve instead of ROC:\n",
    "                                    #shift_auroc.append(metrics.average_precision_score(align_raster[frames[0]:frames[1]], shift_trace) )\n",
    "\n",
    "                                auroc_p.append(prob_from_dist(the_auroc, shift_auroc, hist_range = (0,1), tails = 2))\n",
    "                        else:\n",
    "                            print('\\t** no events found')\n",
    "                            auroc = []\n",
    "                            auroc_p = []\n",
    "                        statstr = 'auroc_' + ''.join([i + ', ' for i in event_type])\n",
    "                        stat_dict[the_cond][the_subj][statstr] = auroc\n",
    "                        statstr = 'auroc_p_' + ''.join([i + ', ' for i in event_type])\n",
    "                        stat_dict[the_cond][the_subj][statstr] = auroc_p\n",
    "                        print('\\n')\n",
    "                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dictionary:\n",
    "\n",
    "fn = 'frame_aligned_data_baclofen.pkl'\n",
    "pickle.dump(stat_dict, open(fn,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### This script analyzes and pools auROC values across events, seperates +/- modulation. Generates frac_dict, which is input data for plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_types = ['rearing left', 'rearing right', 'grooming']\n",
    "print(event_types), \n",
    "print([''.join([j for j in i]) + '_pos_mod' for i in event_types] + [''.join([j for j in i]) + '_neg_mod' for i in event_types])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fraction of modulated neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_types = event_types\n",
    "p_thresh = 0.01\n",
    "roc_thresh = .6\n",
    "align_pad = 200\n",
    "frames = (6200,6200+11500)\n",
    "#frames = (10,5500)\n",
    "\n",
    "frac_dict = dict.fromkeys(stat_dict)\n",
    "\n",
    "for the_cond in stat_dict.keys(): # each genotype\n",
    "    print('\\n',the_cond)\n",
    "\n",
    "    frac_dict[the_cond] = dict.fromkeys([''.join([j for j in i]) + '_pos_mod' for i in event_types] + \n",
    "                                        [''.join([j for j in i]) + '_neg_mod' for i in event_types])\n",
    "    \n",
    "    for i in frac_dict[the_cond]:\n",
    "        frac_dict[the_cond][i] = []\n",
    "    print(frac_dict[the_cond].keys())\n",
    "\n",
    "    for the_subj in sorted(stat_dict[the_cond]): # each subject\n",
    "        print('\\t',the_subj)\n",
    "\n",
    "        trace_mtx = stat_dict[the_cond][the_subj]['trace_mtx']\n",
    "        df_labels = stat_dict[the_cond][the_subj]['labels']\n",
    "        \n",
    "        for event_type in event_types:\n",
    "\n",
    "            # create raster from event points:\n",
    "            align_raster = np.zeros((trace_mtx.shape[0],))\n",
    "            if isinstance(event_type, str):\n",
    "                align_pnts = df_labels.frame.loc[df_labels.label.isin([event_type])].values\n",
    "            else:\n",
    "                align_pnts = df_labels.frame.loc[df_labels.label.isin(event_type)].values\n",
    "            padded_align_pnts = align_pnts\n",
    "            align_raster[padded_align_pnts] = 1\n",
    "            \n",
    "            if isinstance(event_type, tuple):\n",
    "                event_type = ''.join([i + ', ' for i in event_type])[:-2]\n",
    "            print('\\t',event_type)\n",
    "            #print('\\talign points: {}'.format(align_pnts[the_side][event_type]))\n",
    "\n",
    "            # load auROC and auROC_p vectors:\n",
    "            stat_str = 'auroc_p_' + event_type\n",
    "            the_auroc_p = stat_dict[the_cond][the_subj][stat_str]\n",
    "            \n",
    "            stat_str = 'auroc_' + event_type\n",
    "            the_auroc = stat_dict[the_cond][the_subj][stat_str]\n",
    "            \n",
    "            pos_mod = np.intersect1d(np.argwhere(np.asarray(the_auroc_p) <= p_thresh).flatten(), np.argwhere(np.asarray(the_auroc) >= roc_thresh).flatten())\n",
    "            neg_mod = np.intersect1d(np.argwhere(np.asarray(the_auroc_p) <= p_thresh).flatten(), np.argwhere(np.asarray(the_auroc) <= (1-roc_thresh)).flatten())\n",
    "\n",
    "            # positively modulated cells:\n",
    "            stat_str = ''.join([j for j in event_type]) + '_pos_mod'\n",
    "            stat_str = stat_str.replace(', ','')\n",
    "            if len(pos_mod) and sum(align_raster[frames[0]:frames[1]]): # check for modulated cells and zone entries\n",
    "                avg_trace = np.mean(trace_mtx[:,pos_mod], axis=1)\n",
    "                auc = metrics.roc_auc_score(align_raster[frames[0]:frames[1]], avg_trace[frames[0]:frames[1]])\n",
    "                #frac_dict[the_cond][the_exp]['positive_mod_left'].append(auc)\n",
    "                frac_dict[the_cond][stat_str].append(len(pos_mod)/len(the_auroc))\n",
    "                if len(pos_mod==1):\n",
    "                    pos_mod= pos_mod[0]\n",
    "                #frac_dict[the_cond][the_exp]['positive_mod_left'].append(np.mean(the_auroc[pos_mod_l]))\n",
    "            else:\n",
    "                #frac_dict[the_cond][the_exp]['positive_mod_left'].append(np.nan)\n",
    "                frac_dict[the_cond][stat_str].append(0)\n",
    "                \n",
    "            # negatively modulated cells:\n",
    "            stat_str = ''.join([j for j in event_type]) + '_neg_mod'\n",
    "            stat_str = stat_str.replace(', ','')\n",
    "            if len(neg_mod) and sum(align_raster[frames[0]:frames[1]]): # check for modulated cells and zone entries\n",
    "                avg_trace = np.mean(trace_mtx[:, neg_mod], axis=1)\n",
    "                auc = metrics.roc_auc_score(align_raster[frames[0]:frames[1]], avg_trace[frames[0]:frames[1]])\n",
    "                #frac_dict[the_cond][the_exp]['positive_mod_left'].append(auc)\n",
    "                frac_dict[the_cond][stat_str].append(len(neg_mod)/len(the_auroc))\n",
    "                if len(neg_mod==1):\n",
    "                    neg_mod = neg_mod[0]\n",
    "                #frac_dict[the_cond][the_exp]['positive_mod_left'].append(np.mean(the_auroc[pos_mod_l]))\n",
    "            else:\n",
    "                #frac_dict[the_cond][the_exp]['positive_mod_left'].append(np.nan)\n",
    "                frac_dict[the_cond][stat_str].append(0)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### auROC of tuned ensembles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_types = ['nose-to-nose', 'nose-to-ag', 'boxing', 'nose-to-right', 'nose-to-left', \n",
    "               'approach left', 'approach right', 'boxing', ('nose-to-left', 'nose-to-nose', 'nose-to-ag')]\n",
    "print(event_types)\n",
    "print([''.join([j for j in i]) + '_pos_mod' for i in event_types] + [''.join([j for j in i]) + '_neg_mod' for i in event_types])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_types = event_types\n",
    "p_thresh = 0.01\n",
    "roc_thresh = .6\n",
    "align_pad = 200\n",
    "frames = (6200,6200+11500)\n",
    "#frames = (10,5500)\n",
    "\n",
    "frac_dict = dict.fromkeys(stat_dict)\n",
    "\n",
    "for the_cond in stat_dict.keys(): # each genotype\n",
    "    print('\\n',the_cond)\n",
    "\n",
    "    frac_dict[the_cond] = dict.fromkeys([''.join([j for j in i]) + '_pos_mod' for i in event_types] + \n",
    "                                        [''.join([j for j in i]) + '_neg_mod' for i in event_types])\n",
    "    \n",
    "    for i in frac_dict[the_cond]:\n",
    "        frac_dict[the_cond][i] = []\n",
    "    print(frac_dict[the_cond].keys())\n",
    "\n",
    "    for the_subj in sorted(stat_dict[the_cond]): # each subject\n",
    "        print('\\t',the_subj)\n",
    "\n",
    "        trace_mtx = stat_dict[the_cond][the_subj]['trace_mtx']\n",
    "        df_labels = stat_dict[the_cond][the_subj]['labels']\n",
    "        \n",
    "        for event_type in event_types:\n",
    "\n",
    "            # create raster from event points:\n",
    "            align_raster = np.zeros((trace_mtx.shape[0],))\n",
    "            if isinstance(event_type, str):\n",
    "                align_pnts = df_labels.frame.loc[df_labels.label.isin([event_type])].values\n",
    "            else:\n",
    "                align_pnts = df_labels.frame.loc[df_labels.label.isin(event_type)].values\n",
    "            padded_align_pnts = align_pnts\n",
    "            align_raster[padded_align_pnts] = 1\n",
    "            \n",
    "            if isinstance(event_type, tuple):\n",
    "                event_type = ''.join([i + ', ' for i in event_type])[:-2]\n",
    "            print('\\t',event_type)\n",
    "            #print('\\talign points: {}'.format(align_pnts[the_side][event_type]))\n",
    "\n",
    "            # load auROC and auROC_p vectors:\n",
    "            stat_str = 'auroc_p_' + event_type\n",
    "            the_auroc_p = stat_dict[the_cond][the_subj][stat_str]\n",
    "            \n",
    "            stat_str = 'auroc_' + event_type\n",
    "            the_auroc = stat_dict[the_cond][the_subj][stat_str]\n",
    "            \n",
    "            pos_mod = np.intersect1d(np.argwhere(np.asarray(the_auroc_p) <= p_thresh).flatten(), np.argwhere(np.asarray(the_auroc) >= roc_thresh).flatten())\n",
    "            neg_mod = np.intersect1d(np.argwhere(np.asarray(the_auroc_p) <= p_thresh).flatten(), np.argwhere(np.asarray(the_auroc) <= (1-roc_thresh)).flatten())\n",
    "\n",
    "            # positively modulated cells:\n",
    "            stat_str = ''.join([j for j in event_type]) + '_pos_mod'\n",
    "            stat_str = stat_str.replace(', ','')\n",
    "            if len(pos_mod) and sum(align_raster[frames[0]:frames[1]]): # check for modulated cells and zone entries\n",
    "                avg_trace = np.mean(trace_mtx[:,pos_mod], axis=1)\n",
    "                auc = metrics.roc_auc_score(align_raster[frames[0]:frames[1]], avg_trace[frames[0]:frames[1]])\n",
    "                frac_dict[the_cond][stat_str].append(auc)\n",
    "                #frac_dict[the_cond][stat_str].append(len(pos_mod)/len(the_auroc))\n",
    "                #frac_dict[the_cond][stat_str].append(np.mean([the_auroc[i] for i in pos_mod]))\n",
    "                if len(pos_mod==1):\n",
    "                    pos_mod= pos_mod[0]\n",
    "                #frac_dict[the_cond][the_exp]['positive_mod_left'].append(np.mean(the_auroc[pos_mod_l]))\n",
    "            else:\n",
    "                frac_dict[the_cond][stat_str].append(np.nan)\n",
    "                #frac_dict[the_cond][stat_str].append(0)\n",
    "                \n",
    "            # negatively modulated cells:\n",
    "            stat_str = ''.join([j for j in event_type]) + '_neg_mod'\n",
    "            stat_str = stat_str.replace(', ','')\n",
    "            if len(neg_mod) and sum(align_raster[frames[0]:frames[1]]): # check for modulated cells and zone entries\n",
    "                avg_trace = np.mean(trace_mtx[:, neg_mod], axis=1)\n",
    "                auc = metrics.roc_auc_score(align_raster[frames[0]:frames[1]], avg_trace[frames[0]:frames[1]])\n",
    "                frac_dict[the_cond][stat_str].append(auc)\n",
    "                #frac_dict[the_cond][stat_str].append(np.mean([the_auroc[i] for i in neg_mod]))\n",
    "                if len(neg_mod==1):\n",
    "                    neg_mod = neg_mod[0]\n",
    "                #frac_dict[the_cond][the_exp]['positive_mod_left'].append(np.mean(the_auroc[pos_mod_l]))\n",
    "            else:\n",
    "                frac_dict[the_cond][stat_str].append(np.nan)\n",
    "                #frac_dict[the_cond][stat_str].append(0)\n",
    "        \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
